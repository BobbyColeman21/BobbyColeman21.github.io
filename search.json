[
  {
    "objectID": "posts/working-with-graphs/index.html",
    "href": "posts/working-with-graphs/index.html",
    "title": "Making An Effective Graph",
    "section": "",
    "text": "During class this week, we learned how to create bar charts and discussed what makes a graph an effective tool to communicate data.\nTo do this, I made a bar chart showing UNL’s top 10 majors by students in 2024.\nFirst, I loaded the libraries I needed and started with a dataset of all UNL majors.\n\nlibrary(tidyverse)\nlibrary(tidycensus)\nlibrary(janitor)\n\n\nmajors24 &lt;- read_csv(\"https://mattwaite.github.io/datajournalismfiles/enrollment2024.csv\") |&gt; clean_names()\n\nAfter loading the data and cleaning up the columns with clean_names(), I had to prepare the data for our chart. By filtering out any rows I didn’t need and sorting all specializations into their respective majors, I was left with the two rows I needed for the bar chart.\n\ntopmajors24 &lt;- majors24 |&gt; \n  filter(major_name != \"Total\") |&gt; \n  group_by(major_name) |&gt; \n  summarize(\n    total_majors = sum(headcount)\n  ) |&gt; \n  ungroup() |&gt; \n  top_n(10, wt=total_majors)\n\nI threw all the code into ggplot and made a decent graph.\n\nggplot() + \n  geom_bar(data = topmajors24, aes(x=reorder(major_name, total_majors), weight = total_majors)) +\n  coord_flip()\n\n\n\n\n\n\n\n\nIn the end, the chart was weak. It doesn’t tell an interesting story or communicate an insight. A better graph would compare the top 10 majors by students between several years or show us the majors with the lowest student counts ."
  },
  {
    "objectID": "posts/dates-and-unlpd-data/index.html",
    "href": "posts/dates-and-unlpd-data/index.html",
    "title": "Dates and UNLPD Data",
    "section": "",
    "text": "This week we learned about the tedious but important world of cleaning dates. To practice this, I used some UNLPD data to try and find what time of year crime is the worst.\nI started by loading tidyverse and my dataset.\n\nlibrary(tidyverse)\n\n\ncrime &lt;- read.csv(\"crimelogs.csv\")\n\nThe main problem was that the reported date was a character column, not a date column. So I need to use lubridate and the reported column to create a properly formatted date column.\nSo I made the clean column then I created a floor month so I could answer the question of which month had the most calls to UNLPD.\n\ncrime |&gt; \n  mutate(\n    clean_reported = mdy_hm(reported),\n    floor_month = floor_date(clean_reported, \"month\")\n  ) |&gt; \n  group_by(floor_month) |&gt; \n  tally()\n\nFinally, I threw on the arrange function to find which month had the most calls to UNLPD.\n\ncrime |&gt; \n  mutate(\n    clean_reported = mdy_hm(reported),\n    floor_month = floor_date(clean_reported, \"month\")\n  ) |&gt; \n  group_by(floor_month) |&gt; \n  tally() |&gt; \n  arrange(desc(n))\n\nBelow is a quick paragraph presenting my findings:\nAccording to UNLPD data, the first three months of the fall semester have the most reported crimes, with September being the highest. This trend has been present for several years, with the highest number reported in 2018."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Latest Posts",
    "section": "",
    "text": "Dates and UNLPD Data\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nApr 7, 2025\n\n\nBobby Coleman\n\n\n\n\n\n\n\n\n\n\n\n\nPracticing Joining With Ed Dept. Data\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nApr 7, 2025\n\n\nBobby Coleman\n\n\n\n\n\n\n\n\n\n\n\n\nMaking An Effective Graph\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nApr 7, 2025\n\n\nBobby Coleman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/joining/index.html",
    "href": "posts/joining/index.html",
    "title": "Practicing Joining With Ed Dept. Data",
    "section": "",
    "text": "In this assignment, we used Nebraska Department of Education data to practice joining. Like all projects, I started by loading the library and data.\n\nlibrary(tidyverse)\nlibrary(janitor)\n\n\nscores &lt;- read.csv(\"NSCAS_ELA_Proficient_20232024.csv\") |&gt; clean_names()\n\nThis dataset is pretty big and to join it, I need to filter it so I am only left with the columns that I wanted. After doing this, I created the new dataset readingdistricts.\n\nreadingdistricts &lt;- scores |&gt; \n  filter(subgroup_type == \"ALL STUDENTS\") |&gt; \n  filter(level == \"DI\") |&gt; \n  filter(grade == \"8\") |&gt; \n  filter(average_scale_score != \"*\") |&gt; \n  select(level, school_year, county, district, name, subject, grade, average_scale_score)\n\nI then loaded data about student discipline and used filter to get the same columns as I have in the above dataset.\n\ndiscipline &lt;- read.csv(\"StudentDiscipline_20232024.csv\") |&gt; clean_names()\n\n\ndistrictdiscipline &lt;- discipline |&gt; \n  filter(subgroup_description == \"All Students\") |&gt; \n  filter(level == \"DI\") |&gt; \n  filter(students_disciplined_count != \"*\") |&gt;\n   select(level, school_year, county, district, name, total_student_population_count, students_disciplined_count)\n\nBefore joining the two datasets districtdiscipline has 241 rows and readingdistrict has 367.\n\njoineddistricts &lt;- readingdistricts |&gt; \n  inner_join(districtdiscipline)\n\nJoining with `by = join_by(level, school_year, county, district, name)`\n\n\nAfter joining the two datasets into joineddistricts, we are left with 161 rows. This means that all observations that were left out did not match the data in readingdistricts.\nJoining datasets is an essential skill for all data scientists. Throughout my career working with data, I will need to combine different tables to complete a story. Joining is not only an essential skill but is also a great test of my ability to smell data and think logically."
  }
]